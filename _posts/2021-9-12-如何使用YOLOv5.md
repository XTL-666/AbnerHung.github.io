---
redirect_from: /_posts/2021-9-12-å¦‚ä½•ä½¿ç”¨YOLOv5.md/
title: JZoffer
tags:
  - Python
  - AI
  - ComputerVision
---
# å¦‚ä½•å¿«é€Ÿä½¿ç”¨YOLOv5

## å®‰è£…

æœ‰git bashçš„åŒå­¦ç›´æ¥åœ¨bashé‡Œè¾“å…¥

```bash
git clone https://github.com/ultralytics/yolov5
```

å°†å®˜æ–¹æºç å…‹éš†ä¸‹æ¥

æˆ–è€…[ç‚¹å‡»è¿™é‡Œä¸‹è½½](https://k9t-my.sharepoint.com/:u:/g/personal/niimisora_vikuper_com/EYI-7CFam7RKr8i3jw9CozkBX3CyikEgXwGEO4OqfkwyhA?e=1D6FPv)

### Windows

è§£å‹åˆ°æœ¬åœ°åç”¨pycharmæ‰“å¼€æ–‡ä»¶å¤¹ï¼Œé€‰æ‹©å¥½è™šæ‹Ÿç¯å¢ƒ

[![h1pdr8.png](https://z3.ax1x.com/2021/08/28/h1pdr8.png)](https://imgtu.com/i/h1pdr8)

åœ¨ä¸‹æ–¹Terminalä¸­è¿è¡Œï¼š

```bash
pip install -r requirements.txt
```

å¦‚ä¸‹å›¾ï¼š

![h19wS1.png](https://z3.ax1x.com/2021/08/28/h19wS1.png)



å…¨éƒ¨å®‰è£…å®Œæˆåï¼Œè¾“å…¥

```bash
python detect.py --source 0
```

å°†ä¼šè‡ªåŠ¨ä¸‹è½½ä¸€ä¸ª14.1Mçš„`yolov5s.pt`æƒé‡ï¼Œå¯åŠ¨æ‘„åƒå¤´å¼€å¯å®æ—¶æ£€æµ‹

å¯ä»¥çœ‹åˆ°`detect.py`å¯ä»¥é…ç½®çš„ä¸œè¥¿ï¼š

```python
		weights='yolov5s.pt',  # model.pt path(s)
        source='data/images',  # file/dir/URL/glob, 0 for webcam
        imgsz=640,  # inference size (pixels)
        conf_thres=0.25,  # confidence threshold
        iou_thres=0.45,  # NMS IOU threshold
        max_det=1000,  # maximum detections per image
        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu
        view_img=False,  # show results
        save_txt=False,  # save results to *.txt
        save_conf=False,  # save confidences in --save-txt labels
        save_crop=False,  # save cropped prediction boxes
        nosave=False,  # do not save images/videos
        classes=None,  # filter by class: --class 0, or --class 0 2 3
        agnostic_nms=False,  # class-agnostic NMS
        augment=False,  # augmented inference
        visualize=False,  # visualize features
        update=False,  # update all models
        project='runs/detect',  # save results to project/name
        name='exp',  # save results to project/name
        exist_ok=False,  # existing project/name ok, do not increment
        line_thickness=3,  # bounding box thickness (pixels)
        hide_labels=False,  # hide labels
        hide_conf=False,  # hide confidences
        half=False,  # use FP16 half-precision inference
```

### Linux

è¿›å…¥é¡¹ç›®æ‰€åœ¨æ–‡ä»¶å¤¹ï¼Œæ¿€æ´»ç¯å¢ƒï¼Œä½¿ç”¨pipå®‰è£…æ‰€éœ€è½¯ä»¶åŒ…

```bash
cd path/to/yolov5
conda activate path/to/ur_venv_name
pip install -r requirements.txt
```

å¯ç›´æ¥è¿è¡Œ`detect.py` (å½“ç„¶Windows ä¹Ÿå¯)

```
python detect.py
```

å°†ä¼šä¸‹è½½`yolov5s.pt`ï¼Œä½¿ç”¨`data/images`æ–‡ä»¶å¤¹ä¸‹çš„demoæµ‹è¯•

```bash
image 1/2 ./data/images/bus.jpg: 640x480 4 persons, 1 bus, 1 fire hydrant, Done. (0.044s)
image 2/2 ./data/images/zidane.jpg: 384x640 2 persons, 2 ties, Done. (0.022s)
Results saved to runs\detect\exp3
```

å¯ä»¥åœ¨runs\detect\expæ–‡ä»¶å¤¹ä¸‹çœ‹åˆ°ç»“æœï¼ˆå…·ä½“åœ°å€çœ‹è¿è¡ŒåResults saved toåé¢çš„åœ°å€ï¼‰

[![h1ieoD.jpg](https://z3.ax1x.com/2021/08/28/h1ieoD.jpg)](https://imgtu.com/i/h1ieoD)



## æ¥å£

å¯ä»¥çœ‹åˆ°å®˜æ–¹çš„`READMEæ–‡æ¡£`é‡Œæœ‰ä»‹ç»ï¼Œå¯ä»¥ä½¿ç”¨[PyTorch Hub](https://github.com/ultralytics/yolov5/issues/36)è‡ªåŠ¨ä¸‹è½½ï¼ŒåŠ è½½å®˜æ–¹æä¾›çš„æƒé‡

```python
import torch

# Model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5l, yolov5x, custom

# Images
img = 'https://ultralytics.com/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list

# Inference
results = model(img)

# Results
results.print()  # or .show(), .save(), .crop(), .pandas(), etc.
```

`detect.py`ä¹Ÿå¯ä»¥ç›´æ¥è¯»å…¥ç½‘ç»œè§†é¢‘æµè¿›è¡Œæ£€æµ‹ï¼Œå¹¶æŠŠç»“æœæ”¾åˆ° `runs/detect`æ–‡ä»¶å¤¹ä¸‹

```bash
$ python detect.py --source 0  # webcam
                            file.jpg  # image 
                            file.mp4  # video
                            path/  # directory
                            path/*.jpg  # glob
                            'https://youtu.be/NUsoVlDFqZg'  # YouTube
                            'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream
```

# å¦‚ä½•ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒ

## ç›®æ ‡æ£€æµ‹ä¸­ä¸¤ç§å¸¸ç”¨çš„æ•°æ®é›†æ ¼å¼

### VOCæ ¼å¼

```
VOC_ROOT     #æ ¹ç›®å½•
    â”œâ”€â”€ JPEGImages         # å­˜æ”¾æºå›¾ç‰‡
    â”‚     â”œâ”€â”€ imgs1.jpg     
    â”‚     â”œâ”€â”€ imgs2.jpg  
    â”‚     â””â”€â”€ imgs3.jpg
    â”œâ”€â”€ Annotations        # å­˜æ”¾xmlæ–‡ä»¶ï¼Œä¸JPEGImagesä¸­çš„å›¾ç‰‡ä¸€ä¸€å¯¹åº”ï¼Œè§£é‡Šå›¾ç‰‡çš„å†…å®¹ç­‰ç­‰
    â”‚     â”œâ”€â”€ imgs1.xml 
    â”‚     â”œâ”€â”€ imgs2.xml 
    â”‚     â””â”€â”€ imgs3.xml 
    â””â”€â”€ ImageSets          
        â””â”€â”€ Main
          â”œâ”€â”€ train.txt    # txtæ–‡ä»¶ä¸­æ¯ä¸€è¡ŒåŒ…å«ä¸€ä¸ªå›¾ç‰‡çš„åç§°
          â””â”€â”€ val.txt
```

txtæ–‡ä»¶æ ¼å¼ï¼š

æ¯è¡Œä¸ºå›¾ç‰‡çš„åœ°å€

xmlæ–‡ä»¶æ ¼å¼ï¼š

```xml
<annotation>
    <folder>VOC_ROOT</folder>                           
    <filename>imgs1.jpg</filename>  # æ–‡ä»¶å
    <size>                         # å›¾åƒå°ºå¯¸ï¼ˆé•¿å®½ä»¥åŠé€šé“æ•°ï¼‰                      
        <width>500</width>
        <height>332</height>
        <depth>3</depth>
    </size>
    <segmented>1</segmented>       # æ˜¯å¦ç”¨äºåˆ†å‰²ï¼ˆåœ¨å›¾åƒç‰©ä½“è¯†åˆ«ä¸­æ— æ‰€è°“ï¼‰
    <object>                       # æ£€æµ‹åˆ°çš„ç‰©ä½“
        <name>horse</name>         # ç‰©ä½“ç±»åˆ«
        <pose>Unspecified</pose>   # æ‹æ‘„è§’åº¦ï¼Œå¦‚æœæ˜¯è‡ªå·±çš„æ•°æ®é›†å°±Unspecified
        <truncated>0</truncated>   # æ˜¯å¦è¢«æˆªæ–­ï¼ˆ0è¡¨ç¤ºå®Œæ•´)
        <difficult>0</difficult>   # ç›®æ ‡æ˜¯å¦éš¾ä»¥è¯†åˆ«ï¼ˆ0è¡¨ç¤ºå®¹æ˜“è¯†åˆ«ï¼‰
        <bndbox>                   # bounding-boxï¼ˆåŒ…å«å·¦ä¸‹è§’å’Œå³ä¸Šè§’xyåæ ‡ï¼‰
            <xmin>100</xmin>
            <ymin>96</ymin>
            <xmax>355</xmax>
            <ymax>324</ymax>
        </bndbox>
    </object>
    <object>                       # æ£€æµ‹åˆ°å¤šä¸ªç‰©ä½“
        <name>person</name>
        <pose>Unspecified</pose>
        <truncated>0</truncated>
        <difficult>0</difficult>
        <bndbox>
            <xmin>198</xmin>
            <ymin>58</ymin>
            <xmax>286</xmax>
            <ymax>197</ymax>
        </bndbox>
    </object>
</annotation>
```

#### YOLOæ ¼å¼

YOLOæ ¼å¼ä¸VOCæ ¼å¼ç±»ä¼¼

```
DATA_ROOT     #æ ¹ç›®å½•
    â”œâ”€â”€ images        # å­˜æ”¾jsonæ ¼å¼çš„æ ‡æ³¨
    â”‚     â”œâ”€â”€ 000000000001.jpg 
    â”‚     â”œâ”€â”€ 000000000002.jpg 
    â”‚     â””â”€â”€ 000000000003.jpg 
    â””â”€â”€ labels         # å­˜æ”¾å›¾ç‰‡æ–‡ä»¶
    â”‚     â”œâ”€â”€ 000000000001.txt
    â”‚     â”œâ”€â”€ 000000000002.txt
    â”‚     â””â”€â”€ 000000000003.txt
    â””â”€â”€ classes.names
    â””â”€â”€ train.txt 
    â””â”€â”€ valid.txt
    â””â”€â”€ test.txt
```

`train.txt`æ–‡ä»¶æ¯è¡Œä¸ºæ•°æ®åœ°å€

labelsä¸‹çš„txtæ–‡ä»¶æ ¼å¼ä¸º

```
0 0.181640625 0.33469945355191255 0.05859375 0.10109289617486339
1 0.3994140625 0.33060109289617484 0.080078125 0.12021857923497267
0 0.6669921875 0.3128415300546448 0.068359375 0.13934426229508196

```

æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ¡†çš„ä¿¡æ¯

åˆ†åˆ«ä¸ºclass X Y W H 

### COCOæ ¼å¼

```
COCO_ROOT     #æ ¹ç›®å½•
    â”œâ”€â”€ annotations        # å­˜æ”¾jsonæ ¼å¼çš„æ ‡æ³¨
    â”‚     â”œâ”€â”€ instances_train2017.json   
    â”‚     â””â”€â”€ instances_val2017.json
    â””â”€â”€ train2017         # å­˜æ”¾å›¾ç‰‡æ–‡ä»¶
    â”‚     â”œâ”€â”€ 000000000001.jpg 
    â”‚     â”œâ”€â”€ 000000000002.jpg 
    â”‚     â””â”€â”€ 000000000003.jpg 
    â””â”€â”€ val2017        
          â”œâ”€â”€ 000000000004.jpg 
          â””â”€â”€ 000000000005.jpg 
```

jsonæ ¼å¼ï¼š

```json
{
  "info": info, 
  "images": [image], 
  "annotations": [annotation], 
  "categories": [categories],
  "licenses": [license],
}
```

å…¶ä¸­imageæ ¼å¼ä¸º:

```json
# json['images'][0]
{
  'license': 4,
  'file_name': '000000397133.jpg',
  'coco_url': 'http://images.cocodataset.org/val2017/000000397133.jpg',
  'height': 427,
  'width': 640,
  'date_captured': '2013-11-14 17:02:52',
  'flickr_url': 'http://farm7.staticflickr.com/6116/6255196340_da26cf2c9e_z.jpg',
  'id': 397133}
```

categoriesæ ¼å¼ä¸ºï¼š

```json
[
  {'supercategory': 'person', 'id': 1, 'name': 'person'},
  {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'},
  {'supercategory': 'vehicle', 'id': 3, 'name': 'car'},
  {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'},
  {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'},
  {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'},
  {'supercategory': 'vehicle', 'id': 7, 'name': 'train'},
  {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'},
  {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'}
  # ....
]
```

annotationsæ ¼å¼ä¸ºï¼š

```json
{'segmentation': [[0, 0, 60, 0, 60, 40, 0, 40]],
 'area': 240.000,
 'iscrowd': 0,
 'image_id': 289343,
 'bbox': [0., 0., 60., 40.],
 'category_id': 18,
 'id': 1768}
```

## æ ¹æ®æ‰€é€‰çš„æ•°æ®é›†æ ¼å¼é…ç½®yamlæ–‡ä»¶

åœ¨dataç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªyamlæ–‡ä»¶ï¼Œæˆ–è€…å¤åˆ¶å®˜æ–¹æä¾›çš„é…ç½®æ–‡ä»¶è¿›è¡Œåˆ æ”¹

æˆ‘è¿™é‡Œä»¥å£ç½©æ£€æµ‹ä¸ºä¾‹

ä½¿ç”¨YOLOæ ¼å¼çš„æ•°æ®

æ–°å»ºä¸€ä¸ªæ–‡ä»¶ä¸º`mask.yaml`

å†…å®¹è®¾ç½®ä¸ºï¼š

```yaml
train: ./data/mask/train.txt  # train images 
val: ./data/mask/valid.txt  # val images 

# Classes
nc: 3  # number of classes
names: ['With_no_mask',
          'With_mask',
          'Wrong_wearing']  # class names
```

æ³¨ï¼šæˆ‘è¿™ä¸ªæ˜¯è‡ªåˆ¶æ•°æ®é›†ï¼Œæ²¡æœ‰åˆ¶ä½œtesté›†ï¼Œæ•…æ²¡æœ‰è®¾ç½®testæ•°æ®ï¼Œæ­£å¸¸æƒ…å†µä¸‹éœ€è¦è®¾ç½®

namesé‡Œçš„æ˜¯ç±»åˆ«åï¼Œé¡ºåºä¸€å®šè¦ä¸æ•°æ®é›†çš„ä¸€è‡´

## ä¿®æ”¹æ¨¡å‹çš„yamlé…ç½®

ä»¥yolov5sæ¨¡å‹ä¸ºä¾‹

ä¿®æ”¹`models/yolov5s.yaml`ï¼Œåªç”¨ä¿®æ”¹ncä¸ºnumber classeså°±è¡Œäº†ï¼Œæˆ‘è¿™é‡Œ3ç±»ï¼Œæ”¹ä¸º3

```yaml
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 3  # number of classes
depth_multiple: 0.33  # model depth multipleda
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32
  
  ......

```

## ä¿®æ”¹train.py

åœ¨`train.py`çš„å¤§æ¦‚420è¡Œçš„ä½ç½®ï¼Œä¿®æ”¹`parse_opt`çš„é»˜è®¤é…ç½®

```python
parser = argparse.ArgumentParser()
# åŠ è½½çš„æƒé‡æ–‡ä»¶,è‹¥æ˜¯ç¬¬ä¸€æ¬¡è®­ç»ƒï¼Œä¸åŠ è½½æƒé‡ï¼ŒæŠŠè¿™é‡Œdefaultæ”¹ä¸º''
parser.add_argument('--weights', type=str, default='', help='initial weights path')
# æ¨¡å‹é…ç½®æ–‡ä»¶ï¼Œç½‘ç»œç»“æ„ï¼Œä½¿ç”¨ä¿®æ”¹å¥½çš„yolov5s.yamlæ–‡ä»¶
parser.add_argument('--cfg', type=str, default='models/yolov5s.yaml', help='model.yaml path')
# æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼Œæ•°æ®é›†è·¯å¾„ï¼Œç±»åç­‰ï¼Œä½¿ç”¨æ•°æ®é›†æ–¹é¢çš„mask.yamlæ–‡ä»¶
parser.add_argument('--data', type=str, default='data/mask.yaml', help='data.yaml path')
# è¶…å‚æ•°æ–‡ä»¶
parser.add_argument('--hyp', type=str, default='data/hyp.scratch.yaml', help='hyperparameters path')
# è®­ç»ƒæ€»è½®æ¬¡ï¼Œ1ä¸ªepochç­‰äºä½¿ç”¨è®­ç»ƒé›†ä¸­çš„å…¨éƒ¨æ ·æœ¬è®­ç»ƒä¸€æ¬¡ï¼Œå€¼è¶Šå¤§æ¨¡å‹è¶Šç²¾ç¡®ï¼Œè®­ç»ƒæ—¶é—´ä¹Ÿè¶Šé•¿ã€‚é»˜è®¤300ï¼Œæˆ‘è¿™é‡Œæµ‹è¯•10è½®æ”¹ä¸º10
parser.add_argument('--epochs', type=int, default=10)
# æ‰¹æ¬¡å¤§å°ï¼Œä¸€æ¬¡è®­ç»ƒæ‰€é€‰å–çš„æ ·æœ¬æ•°ï¼Œæ˜¾å¡ä¸å¤ªè¡Œçš„è¯ï¼Œå°±è°ƒå°ç‚¹ï¼Œå»ºè®®å…ˆè°ƒå°ç‚¹ï¼Œèƒ½è·‘èµ·æ¥å†åŠ ï¼Œæˆ‘è¿™é‡Œè°ƒæˆäº†2ï¼Œè·‘èµ·æ¥åè¯æ˜å¤ªå°äº†T.T
parser.add_argument('--batch-size', type=int, default=2, help='total batch size for all GPUs')
# è¾“å…¥å›¾ç‰‡åˆ†è¾¨ç‡å¤§å°ï¼Œnargs='+'è¡¨ç¤ºå‚æ•°å¯è®¾ç½®ä¸€ä¸ªæˆ–å¤šä¸ª,æˆ‘è¿™é‡Œæ”¹ä¸ºäº†ç»å…¸çš„416ğŸ˜¹
parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=416, help='train, val image size (pixels)')
# æ˜¯å¦é‡‡ç”¨çŸ©å½¢è®­ç»ƒï¼Œé»˜è®¤Falseï¼Œå¼€å¯åå¯æ˜¾è‘—çš„å‡å°‘æ¨ç†æ—¶é—´
parser.add_argument('--rect', action='store_true', help='rectangular training')
# æ¥ç€æ‰“æ–­è®­ç»ƒä¸Šæ¬¡çš„ç»“æœæ¥ç€è®­ç»ƒ
parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')
# ä¸ä¿å­˜æ¨¡å‹ï¼Œé»˜è®¤False
parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')
# ä¸è¿›è¡Œtestï¼Œé»˜è®¤False
parser.add_argument('--notest', action='store_true', help='only test final epoch')
# ä¸è‡ªåŠ¨è°ƒæ•´anchorï¼Œé»˜è®¤False
parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')
# æ˜¯å¦è¿›è¡Œè¶…å‚æ•°è¿›åŒ–ï¼Œé»˜è®¤False
parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')
# è°·æ­Œäº‘ç›˜bucketï¼Œä¸€èˆ¬ä¸ä¼šç”¨åˆ°
parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')
# æ˜¯å¦æå‰ç¼“å­˜å›¾ç‰‡åˆ°å†…å­˜ï¼Œä»¥åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œé»˜è®¤False
parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')
# é€‰ç”¨åŠ æƒå›¾åƒè¿›è¡Œè®­ç»ƒ
parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')
# è®­ç»ƒçš„è®¾å¤‡ï¼Œcpuï¼›0(è¡¨ç¤ºä¸€ä¸ªgpuè®¾å¤‡cuda:0)ï¼›0,1,2,3(å¤šä¸ªgpuè®¾å¤‡)ã€‚å€¼ä¸ºç©ºæ—¶ï¼Œè®­ç»ƒæ—¶é»˜è®¤ä½¿ç”¨è®¡ç®—æœºè‡ªå¸¦çš„æ˜¾å¡æˆ–CPU
parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
# æ˜¯å¦è¿›è¡Œå¤šå°ºåº¦è®­ç»ƒï¼Œé»˜è®¤False
parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')
# æ•°æ®é›†æ˜¯å¦åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œé»˜è®¤False
parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')
# æ˜¯å¦ä½¿ç”¨adamä¼˜åŒ–å™¨
parser.add_argument('--adam', action='store_true', help='use torch.optim.Adam() optimizer')
# æ˜¯å¦ä½¿ç”¨è·¨å¡åŒæ­¥BN,åœ¨DDPæ¨¡å¼ä½¿ç”¨
parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')
# gpuç¼–å·
parser.add_argument('--local_rank', type=int, default=-1, help='DDP parameter, do not modify')
# W&Bè®°å½•çš„å›¾åƒæ•°ï¼Œæœ€å¤§ä¸º100
parser.add_argument('--log-imgs', type=int, default=16, help='number of images for W&B logging, max 100')
# è®°å½•æœ€ç»ˆè®­ç»ƒçš„æ¨¡å‹ï¼Œå³last.pt
parser.add_argument('--log-artifacts', action='store_true', help='log artifacts, i.e. final trained model')
# dataloaderçš„æœ€å¤§workeræ•°é‡ï¼Œå»ºè®®å…ˆè°ƒæˆ0ï¼Œèƒ½è·‘èµ·æ¥å†åŠ 
parser.add_argument('--workers', type=int, default=0, help='maximum number of dataloader workers')
# è®­ç»ƒç»“æœæ‰€å­˜æ”¾çš„è·¯å¾„ï¼Œé»˜è®¤ä¸ºruns/train
parser.add_argument('--project', default='runs/train', help='save to project/name')
# è®­ç»ƒç»“æœæ‰€åœ¨æ–‡ä»¶å¤¹çš„åç§°ï¼Œé»˜è®¤ä¸ºexp
parser.add_argument('--name', default='exp', help='save to project/name')
# è‹¥ç°æœ‰çš„project/nameå­˜åœ¨ï¼Œåˆ™ä¸è¿›è¡Œé€’å¢
parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
opt = parser.parse_args()
```

## å¯ä»¥ç›´æ¥è¿è¡Œtrain.pyäº†

è·‘èµ·æ¥æ˜¯è¿™æ ·çš„ï¼Œå¯ä»¥çœ‹åˆ°æ‰ç”¨äº†ä¸åˆ°0.5Gçš„æ˜¾å­˜ï¼Œæ‰3ä¸ªè¿­ä»£ä¸€ç§’ï¼Œè¯´æ˜batch_sizeç¡®å®è°ƒå¾—å¤ªå°äº†

[![h1lzTJ.png](https://z3.ax1x.com/2021/08/28/h1lzTJ.png)](https://imgtu.com/i/h1lzTJ)

è·‘å®Œåçš„summaryï¼š

[![h11KfI.png](https://z3.ax1x.com/2021/08/28/h11KfI.png)](https://imgtu.com/i/h11KfI)

å¯è§æˆ‘è¿™ä¸ªæ•°æ®é›†å¾ˆä¸å‡è¡¡

å¦‚æœé…ç½®äº†wanbè¿˜èƒ½çœ‹åˆ°å„ç§æŠ¥å‘Šï¼ˆæ¯”tensorboardè¯¦ç»†å¾ˆå¤šï¼‰

[![h11010.png](https://z3.ax1x.com/2021/08/28/h11010.png)](https://imgtu.com/i/h11010)

[![h11h1x.png](https://z3.ax1x.com/2021/08/28/h11h1x.png)](https://imgtu.com/i/h11h1x)

